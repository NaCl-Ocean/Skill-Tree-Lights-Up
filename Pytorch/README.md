# Pytorch

- [lecture 0](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_0.md)：张量的概念，创建，操作(切分，合并)
- [lecture 1](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_1.md)：计算图的概念与autograd
- [lecture 2](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_2.md)：读取数据，Dataset与Dataloader
- [lecture 3](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_3.md)：搭建模型，`torch.nn.Module`
- [lecture 4](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_3.md)：模型初始化，`torch.nn.init`
- [lecture 5](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_5.md)：Pytorch中的18个loss function，`torch.nn`
- [lecture 6](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_6.md)：Pytorch中的optimizer，`torch.optim`
- [lecture 7](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_7.md)：Pyotrch中的scheduler，`torch.optim.lr_schedule`
- [lecture 8](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_8.md)：Tensorboard使用，`torch.utils.tensorboard`
- [lecture 9](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_9.md)：Pytorch中的hook函数
- [lecture 10](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_10.md)：pytorch中的正则化策略
- [lecture 11](https://github.com/NaCl-Ocean/Skill-Tree-Lights-Up/blob/master/Python/pytorch/lecture_11.md)：pytorch 并行训练（DistributedParallel）